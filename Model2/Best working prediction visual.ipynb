{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11031611-795c-424b-9b30-941e7c330262",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized keyword arguments: ['batch_shape']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display, clear_output\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Load your trained model for 5-minute future prediction\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m model_5min \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_5min.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Define the ticker symbol\u001b[39;00m\n\u001b[0;32m     16\u001b[0m ticker \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^NSEBANK\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\Desktop\\Minor project\\test_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Desktop\\Minor project\\test_venv\\lib\\site-packages\\keras\\engine\\input_layer.py:152\u001b[0m, in \u001b[0;36mInputLayer.__init__\u001b[1;34m(self, input_shape, batch_size, dtype, input_tensor, sparse, name, ragged, type_spec, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m         input_shape \u001b[38;5;241m=\u001b[39m batch_input_shape[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse \u001b[38;5;129;01mand\u001b[39;00m ragged:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set both sparse and ragged to True in a Keras input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized keyword arguments: ['batch_shape']"
     ]
    }
   ],
   "source": [
    "# best working till now 23-09-24\n",
    "\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "from tensorflow.keras.models import load_model\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Load your trained model for 5-minute future prediction\n",
    "model_5min = load_model('model_5min.h5')\n",
    "\n",
    "# Define the ticker symbol\n",
    "ticker = \"^NSEBANK\"\n",
    "\n",
    "# Fetch historical Bank Nifty data (last 60 minutes of data in 5-minute intervals)\n",
    "historical_data = yf.download(ticker, period='1d', interval='5m')\n",
    "\n",
    "# Preprocess the historical data\n",
    "if not historical_data.empty:\n",
    "    historical_data = historical_data[['Open', 'High', 'Low', 'Close']]\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    # Fit the scaler only on historical data\n",
    "    scaled_historical_data = scaler.fit_transform(historical_data)\n",
    "else:\n",
    "    print(\"No historical data found!\")\n",
    "\n",
    "# Initialize empty lists to store timestamps and candlestick data\n",
    "timestamps = list(historical_data.index[-12:])  # Initialize with last 12 (5-minute) data points (60 minutes of historical timestamps)\n",
    "open_prices = list(historical_data['Open'][-12:])  # Initialize with last 12 (5-minute) Open prices\n",
    "high_prices = list(historical_data['High'][-12:])  # Initialize with last 12 (5-minute) High prices\n",
    "low_prices = list(historical_data['Low'][-12:])    # Initialize with last 12 (5-minute) Low prices\n",
    "actual_closes = list(historical_data['Close'][-12:])  # Initialize with the last actual 12 close prices\n",
    "predicted_closes = []  # List to store predicted close prices\n",
    "predicted_timestamps = []  # List to store timestamps for predicted future close prices\n",
    "\n",
    "# Function for live prediction\n",
    "def predict_live_data():\n",
    "    live_data_accumulated = historical_data[-12:]  # Start with the last 60 minutes of historical data (12 intervals of 5 minutes)\n",
    "\n",
    "    while True:\n",
    "        # Fetch live data (5-minute interval)\n",
    "        live_data = yf.download(ticker, period='1d', interval='5m')\n",
    "\n",
    "        # Check if live data is empty\n",
    "        if live_data.empty:\n",
    "            print(\"No live data found! Skipping this cycle.\")\n",
    "            time.sleep(300)  # Wait 5 minutes and try again\n",
    "            continue\n",
    "\n",
    "        # Preprocess live data\n",
    "        live_data = live_data[['Open', 'High', 'Low', 'Close']]\n",
    "\n",
    "        # Append new live data to accumulated data and keep only the last 60 minutes (12 data points)\n",
    "        live_data_accumulated = pd.concat([live_data_accumulated, live_data])[-12:]\n",
    "\n",
    "        # Apply the scaler to the live data\n",
    "        try:\n",
    "            scaled_live_data = scaler.transform(live_data_accumulated)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error scaling live data: {e}\")\n",
    "            time.sleep(300)  # Wait 5 minutes and try again\n",
    "            continue\n",
    "\n",
    "        # Ensure there's enough data for prediction (12 data points of 5-minute intervals)\n",
    "        if len(scaled_live_data) < 12:\n",
    "            print(\"Not enough data for prediction! Waiting for more data.\")\n",
    "            time.sleep(300)\n",
    "            continue\n",
    "\n",
    "        # The model should now predict 5 minutes into the future\n",
    "        X_live = np.array([scaled_live_data[-12:]])\n",
    "\n",
    "        # Reshape to match the LSTM model's input shape\n",
    "        X_live = np.reshape(X_live, (X_live.shape[0], X_live.shape[1], 4))\n",
    "\n",
    "        # Make prediction for 5 minutes into the future\n",
    "        predicted_price = model_5min.predict(X_live)\n",
    "\n",
    "        # Inverse transform to get the actual predicted price (predicted 5-min ahead close price)\n",
    "        predicted_close_price = scaler.inverse_transform([[0, 0, 0, predicted_price[0][0]]])[0][3]\n",
    "\n",
    "        # Get the current timestamp and other OHLC values from live data\n",
    "        current_time = live_data.index[-1]\n",
    "        open_price = live_data['Open'][-1]\n",
    "        high_price = live_data['High'][-1]\n",
    "        low_price = live_data['Low'][-1]\n",
    "        actual_close_price = live_data['Close'][-1]  # Actual close price\n",
    "\n",
    "        # Store predicted values for 5 minutes in the future\n",
    "        predicted_timestamps.append(current_time + pd.Timedelta(minutes=5))  # Add 5 minutes to current time\n",
    "        predicted_closes.append(predicted_close_price)\n",
    "\n",
    "        # Append the OHLC values and actual close price to the lists\n",
    "        timestamps.append(current_time)\n",
    "        open_prices.append(open_price)\n",
    "        high_prices.append(high_price)\n",
    "        low_prices.append(low_price)\n",
    "        actual_closes.append(actual_close_price)\n",
    "\n",
    "        # Output predicted price\n",
    "        print(f\"Predicted Close Price for 5 minutes ahead: {predicted_close_price}\")\n",
    "        print(f\"Actual Close Price: {actual_close_price}\")\n",
    "\n",
    "        # Create a new candlestick figure\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Add candlestick trace with real open, high, low, and actual close prices\n",
    "        fig.add_trace(go.Candlestick(x=timestamps,\n",
    "                                     open=open_prices,\n",
    "                                     high=high_prices,\n",
    "                                     low=low_prices,\n",
    "                                     close=actual_closes,\n",
    "                                     name='Actual Candlestick'))\n",
    "\n",
    "        # Overlay predicted candlesticks using predicted close prices\n",
    "        # We replicate open, high, low using the predicted close (since we don't have future OHLC values)\n",
    "        fig.add_trace(go.Candlestick(x=predicted_timestamps,\n",
    "                                     open=predicted_closes,  # Use the predicted close for open, high, low\n",
    "                                     high=predicted_closes,\n",
    "                                     low=predicted_closes,\n",
    "                                     close=predicted_closes,\n",
    "                                     name='Predicted Candlestick',\n",
    "                                     increasing_line_color='blue', decreasing_line_color='blue'))\n",
    "\n",
    "        # Update layout with hovermode for both x and y axes\n",
    "        fig.update_layout(\n",
    "            title=\"Live 5-Minute Interval Candlestick with Prediction (5 Min Ahead)\",\n",
    "            xaxis_title=\"Timestamp\",\n",
    "            yaxis_title=\"Price\",\n",
    "            hovermode=\"x unified\",  # Unified hover mode on x-axis\n",
    "            hoverlabel=dict(namelength=-1),  # Show full text\n",
    "        )\n",
    "\n",
    "        # Clear the previous plot and display the updated candlestick chart\n",
    "        clear_output(wait=True)\n",
    "        display(fig)\n",
    "\n",
    "        # Wait for 5 minutes before running the prediction again\n",
    "        time.sleep(60)\n",
    "\n",
    "# Start the live prediction and graph update\n",
    "predict_live_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c4dff60-d78f-4050-925c-c8d7ef7c0a1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized keyword arguments: ['batch_shape']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_5min \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_5min.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model_5min\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32m~\\Desktop\\Minor project\\test_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Desktop\\Minor project\\test_venv\\lib\\site-packages\\keras\\engine\\input_layer.py:152\u001b[0m, in \u001b[0;36mInputLayer.__init__\u001b[1;34m(self, input_shape, batch_size, dtype, input_tensor, sparse, name, ragged, type_spec, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m         input_shape \u001b[38;5;241m=\u001b[39m batch_input_shape[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse \u001b[38;5;129;01mand\u001b[39;00m ragged:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set both sparse and ragged to True in a Keras input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized keyword arguments: ['batch_shape']"
     ]
    }
   ],
   "source": [
    "model_5min = load_model('model_5min.h5', compile=False)\n",
    "model_5min.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f6b5c-8bff-4211-a4c2-7a620230b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "from tensorflow.keras.models import load_model\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Load your trained model for 5-minute future prediction\n",
    "model_5min = load_model('model_5min.h5')\n",
    "\n",
    "# Define the ticker symbol\n",
    "ticker = \"^NSEBANK\"\n",
    "\n",
    "# Fetch historical Bank Nifty data (last 60 minutes of data in 5-minute intervals)\n",
    "historical_data = yf.download(ticker, period='1d', interval='5m')\n",
    "\n",
    "# Preprocess the historical data\n",
    "if not historical_data.empty:\n",
    "    historical_data = historical_data[['Open', 'High', 'Low', 'Close']]\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    # Fit the scaler only on historical data\n",
    "    scaled_historical_data = scaler.fit_transform(historical_data)\n",
    "else:\n",
    "    print(\"No historical data found!\")\n",
    "\n",
    "# Initialize empty lists to store timestamps and candlestick data\n",
    "timestamps = list(historical_data.index[-12:])  # Initialize with last 12 (5-minute) data points (60 minutes of historical timestamps)\n",
    "open_prices = list(historical_data['Open'][-12:])  # Initialize with last 12 (5-minute) Open prices\n",
    "high_prices = list(historical_data['High'][-12:])  # Initialize with last 12 (5-minute) High prices\n",
    "low_prices = list(historical_data['Low'][-12:])    # Initialize with last 12 (5-minute) Low prices\n",
    "predicted_closes = []  # List to store predicted close prices\n",
    "actual_closes = list(historical_data['Close'][-12:])  # Initialize with the last actual 12 close prices\n",
    "\n",
    "# Function for live prediction\n",
    "def predict_live_data():\n",
    "    live_data_accumulated = historical_data[-12:]  # Start with the last 60 minutes of historical data (12 intervals of 5 minutes)\n",
    "\n",
    "    while True:\n",
    "        # Fetch live data (5-minute interval)\n",
    "        live_data = yf.download(ticker, period='1d', interval='1m')\n",
    "\n",
    "        # Check if live data is empty\n",
    "        if live_data.empty:\n",
    "            print(\"No live data found! Skipping this cycle.\")\n",
    "            time.sleep(300)  # Wait 5 minutes and try again\n",
    "            continue\n",
    "\n",
    "        # Preprocess live data\n",
    "        live_data = live_data[['Open', 'High', 'Low', 'Close']]\n",
    "\n",
    "        # Append new live data to accumulated data and keep only the last 60 minutes (12 data points)\n",
    "        live_data_accumulated = pd.concat([live_data_accumulated, live_data])[-12:]\n",
    "\n",
    "        # Apply the scaler to the live data\n",
    "        try:\n",
    "            scaled_live_data = scaler.transform(live_data_accumulated)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error scaling live data: {e}\")\n",
    "            time.sleep(300)  # Wait 5 minutes and try again\n",
    "            continue\n",
    "\n",
    "        # Ensure there's enough data for prediction (12 data points of 5-minute intervals)\n",
    "        if len(scaled_live_data) < 12:\n",
    "            print(\"Not enough data for prediction! Waiting for more data.\")\n",
    "            time.sleep(300)\n",
    "            continue\n",
    "\n",
    "        # The model should now predict 5 minutes into the future\n",
    "        X_live = np.array([scaled_live_data[-12:]])\n",
    "\n",
    "        # Reshape to match the LSTM model's input shape\n",
    "        X_live = np.reshape(X_live, (X_live.shape[0], X_live.shape[1], 4))\n",
    "\n",
    "        # Make prediction for 5 minutes into the future\n",
    "        predicted_price = model_5min.predict(X_live)\n",
    "\n",
    "        # Inverse transform to get the actual predicted price (predicted 5-min ahead close price)\n",
    "        predicted_close_price = scaler.inverse_transform([[0, 0, 0, predicted_price[0][0]]])[0][3]\n",
    "\n",
    "        # Get the current timestamp and other OHLC values from live data\n",
    "        current_time = live_data.index[-1]\n",
    "        open_price = live_data['Open'][-1]\n",
    "        high_price = live_data['High'][-1]\n",
    "        low_price = live_data['Low'][-1]\n",
    "        actual_close_price = live_data['Close'][-1]  # Actual close price\n",
    "\n",
    "        # Append the OHLC values and predicted close price to the lists\n",
    "        timestamps.append(current_time)\n",
    "        open_prices.append(open_price)\n",
    "        high_prices.append(high_price)\n",
    "        low_prices.append(low_price)\n",
    "        predicted_closes.append(predicted_close_price)\n",
    "        actual_closes.append(actual_close_price)  # Append the actual close price as well\n",
    "\n",
    "        # Add the predicted price to the live data to simulate prediction of future 5-minute close\n",
    "        new_row = pd.DataFrame([[open_price, high_price, low_price, predicted_close_price]],\n",
    "                               columns=['Open', 'High', 'Low', 'Close'], index=[current_time])\n",
    "        live_data_accumulated = pd.concat([live_data_accumulated, new_row])[-12:]\n",
    "\n",
    "        # Output predicted price\n",
    "        print(f\"Predicted Close Price for 5 minutes ahead: {predicted_close_price}\")\n",
    "        print(f\"Actual Close Price: {actual_close_price}\")\n",
    "\n",
    "        # Create a new candlestick figure\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Add candlestick trace with real open, high, low, and actual close prices\n",
    "        fig.add_trace(go.Candlestick(x=timestamps,\n",
    "                                     open=open_prices,\n",
    "                                     high=high_prices,\n",
    "                                     low=low_prices,\n",
    "                                     close=actual_closes,\n",
    "                                     name='Actual Candlestick'))\n",
    "\n",
    "        # Overlay predicted close prices as a separate line\n",
    "        fig.add_trace(go.Scatter(x=timestamps, \n",
    "                                 y=predicted_closes, \n",
    "                                 mode='lines+markers', \n",
    "                                 name='Predicted Close', \n",
    "                                 line=dict(color='blue', dash='dash')))\n",
    "\n",
    "        # Update layout with hovermode for both x and y axes\n",
    "        fig.update_layout(\n",
    "            title=\"Live 5-Minute Interval Candlestick with Prediction (5 Min Ahead)\",\n",
    "            xaxis_title=\"Timestamp\",\n",
    "            yaxis_title=\"Price\",\n",
    "            hovermode=\"x unified\",  # Unified hover mode on x-axis\n",
    "            hoverlabel=dict(namelength=-1),  # Show full text\n",
    "        )\n",
    "\n",
    "        # Clear the previous plot and display the updated candlestick chart\n",
    "        clear_output(wait=True)\n",
    "        display(fig)\n",
    "\n",
    "        # Wait for 5 minutes before running the prediction again\n",
    "        time.sleep(5)\n",
    "\n",
    "# Start the live prediction and graph update\n",
    "predict_live_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fefd9da-9d59-4b89-8641-05cb8e343b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "from tensorflow.keras.models import load_model\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Load your trained model for 5-minute future prediction\n",
    "model_5min = load_model('model_5min.h5')\n",
    "\n",
    "# Define the ticker symbol\n",
    "ticker = \"^NSEBANK\"\n",
    "\n",
    "# Fetch historical Bank Nifty data (last 60 minutes of data in 5-minute intervals)\n",
    "historical_data = yf.download(ticker, period='1d', interval='5m')\n",
    "\n",
    "# Preprocess the historical data\n",
    "if not historical_data.empty:\n",
    "    historical_data = historical_data[['Open', 'High', 'Low', 'Close']]\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    # Fit the scaler only on historical data\n",
    "    scaled_historical_data = scaler.fit_transform(historical_data)\n",
    "else:\n",
    "    print(\"No historical data found!\")\n",
    "\n",
    "# Initialize empty lists to store timestamps and candlestick data\n",
    "timestamps = list(historical_data.index[-12:])  # Initialize with last 12 (5-minute) data points (60 minutes of historical timestamps)\n",
    "open_prices = list(historical_data['Open'][-12:])  # Initialize with last 12 (5-minute) Open prices\n",
    "high_prices = list(historical_data['High'][-12:])  # Initialize with last 12 (5-minute) High prices\n",
    "low_prices = list(historical_data['Low'][-12:])    # Initialize with last 12 (5-minute) Low prices\n",
    "predicted_closes = []  # List to store predicted close prices\n",
    "\n",
    "# Function for live prediction\n",
    "def predict_live_data():\n",
    "    live_data_accumulated = historical_data[-12:]  # Start with the last 60 minutes of historical data (12 intervals of 5 minutes)\n",
    "\n",
    "    while True:\n",
    "        # Fetch live data (5-minute interval)\n",
    "        live_data = yf.download(ticker, period='1d', interval='5m')\n",
    "\n",
    "        # Check if live data is empty\n",
    "        if live_data.empty:\n",
    "            print(\"No live data found! Skipping this cycle.\")\n",
    "            time.sleep(300)  # Wait 5 minutes and try again\n",
    "            continue\n",
    "\n",
    "        # Preprocess live data\n",
    "        live_data = live_data[['Open', 'High', 'Low', 'Close']]\n",
    "\n",
    "        # Append new live data to accumulated data and keep only the last 60 minutes (12 data points)\n",
    "        live_data_accumulated = pd.concat([live_data_accumulated, live_data])[-12:]\n",
    "\n",
    "        # Apply the scaler to the live data\n",
    "        try:\n",
    "            scaled_live_data = scaler.transform(live_data_accumulated)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error scaling live data: {e}\")\n",
    "            time.sleep(300)  # Wait 5 minutes and try again\n",
    "            continue\n",
    "\n",
    "        # Ensure there's enough data for prediction (12 data points of 5-minute intervals)\n",
    "        if len(scaled_live_data) < 12:\n",
    "            print(\"Not enough data for prediction! Waiting for more data.\")\n",
    "            time.sleep(300)\n",
    "            continue\n",
    "\n",
    "        # The model should now predict 5 minutes into the future\n",
    "        X_live = np.array([scaled_live_data[-12:]])\n",
    "\n",
    "        # Reshape to match the LSTM model's input shape\n",
    "        X_live = np.reshape(X_live, (X_live.shape[0], X_live.shape[1], 4))\n",
    "\n",
    "        # Make prediction for 5 minutes into the future\n",
    "        predicted_price = model_5min.predict(X_live)\n",
    "\n",
    "        # Inverse transform to get the actual predicted price (predicted 5-min ahead close price)\n",
    "        predicted_close_price = scaler.inverse_transform([[0, 0, 0, predicted_price[0][0]]])[0][3]\n",
    "\n",
    "        # Get the current timestamp and other OHLC values from live data\n",
    "        current_time = live_data.index[-1]\n",
    "        open_price = live_data['Open'][-1]\n",
    "        high_price = live_data['High'][-1]\n",
    "        low_price = live_data['Low'][-1]\n",
    "\n",
    "        # Append the OHLC values and predicted close price to the lists\n",
    "        timestamps.append(current_time)\n",
    "        open_prices.append(open_price)\n",
    "        high_prices.append(high_price)\n",
    "        low_prices.append(low_price)\n",
    "        predicted_closes.append(predicted_close_price)\n",
    "\n",
    "        # Add the predicted price to the live data to simulate prediction of future 5-minute close\n",
    "        new_row = pd.DataFrame([[open_price, high_price, low_price, predicted_close_price]],\n",
    "                               columns=['Open', 'High', 'Low', 'Close'], index=[current_time])\n",
    "        live_data_accumulated = pd.concat([live_data_accumulated, new_row])[-12:]\n",
    "\n",
    "        # Output predicted price\n",
    "        print(f\"Predicted Close Price for 5 minutes ahead: {predicted_close_price}\")\n",
    "\n",
    "        # Create a new candlestick figure\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Add candlestick trace with real open, high, low, and predicted close prices\n",
    "        fig.add_trace(go.Candlestick(x=timestamps,\n",
    "                                     open=open_prices,\n",
    "                                     high=high_prices,\n",
    "                                     low=low_prices,\n",
    "                                     close=predicted_closes,\n",
    "                                     name='Candlestick'))\n",
    "\n",
    "        # Update layout with hovermode for both x and y axes\n",
    "        fig.update_layout(\n",
    "            title=\"Live 5-Minute Interval Candlestick Prediction (5 Min Ahead)\",\n",
    "            xaxis_title=\"Timestamp\",\n",
    "            yaxis_title=\"Price\",\n",
    "            hovermode=\"x unified\",  # Unified hover mode on x-axis\n",
    "            hoverlabel=dict(namelength=-1),  # Show full text\n",
    "        )\n",
    "\n",
    "        # Clear the previous plot and display the updated candlestick chart\n",
    "        clear_output(wait=True)\n",
    "        display(fig)\n",
    "\n",
    "        # Wait for 5 minutes before running the prediction again\n",
    "        time.sleep(5)\n",
    "\n",
    "# Start the live prediction and graph update\n",
    "predict_live_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e4381-e93a-4332-97ca-8ced5419549e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minorporject",
   "language": "python",
   "name": "minorporject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
